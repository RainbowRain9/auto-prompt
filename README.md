# AI Prompt Optimization Platform

<div align="center">

![AI Prompt Optimizer](https://img.shields.io/badge/AI-Prompt%20Optimizer-blue?style=for-the-badge&logo=openai)
![License](https://img.shields.io/badge/License-LGPL-green?style=for-the-badge)
![.NET](https://img.shields.io/badge/.NET-9.0-purple?style=for-the-badge&logo=dotnet)
![React](https://img.shields.io/badge/React-19.1.0-blue?style=for-the-badge&logo=react)

**Professional AI prompt optimization, debugging, and sharing platform**

[üöÄ Quick Start](#quick-start) ‚Ä¢ [üìñ Features](#features) ‚Ä¢ [üõ†Ô∏è Tech Stack](#tech-stack) ‚Ä¢ [üì¶ Deployment Guide](#deployment-guide) ‚Ä¢ [ü§ù Contribution Guide](#contribution-guide)

</div>

---

## üìã Project Overview

AI Prompt Optimization Platform is a professional prompt engineering tool designed to help users optimize AI model prompts, enhancing the effectiveness and accuracy of AI interactions. The platform integrates intelligent optimization algorithms, deep reasoning analysis, visualization debugging tools, and community sharing features, providing comprehensive prompt optimization solutions for AI application developers and content creators.

### üéØ Core Values

- **Intelligent Optimization**: Automatically analyze and optimize prompt structures based on advanced AI algorithms
- **Deep Reasoning**: Provide multi-dimensional thinking analysis to deeply understand user needs
- **Community Sharing**: Discover and share high-quality prompt templates, exchange experiences with community users
- **Visualization Debugging**: Robust debugging environment with real-time preview of prompt effects

## ‚ú® Features

### üß† Intelligent Prompt Optimization

- **Automatic Structure Analysis**: Deeply analyze the semantic structure and logical relationships of prompts
- **Multi-Dimensional Optimization**: Optimize from multiple dimensions such as clarity, accuracy, and completeness
- **Deep Reasoning Mode**: Enable AI deep thinking to provide detailed analysis processes
- **Real-Time Generation**: Stream output of optimization results, view the generation process in real-time

### üìö Prompt Template Management

- **Template Creation**: Save optimized prompts as reusable templates
- **Tag Classification**: Support multi-tag classification management for easy searching and organizing
- **Favorites Feature**: Favorite templates for quick access to commonly used prompts
- **Usage Statistics**: Track template usage and feedback on effectiveness

### üåê Community Sharing Platform

- **Public Sharing**: Share high-quality templates with community users
- **Popularity Ranking**: Display popular templates based on views, likes, etc.
- **Search Discovery**: Powerful search functionality to quickly find needed templates
- **Interactive Features**: Social features such as likes, comments, and favorites

### üîß Debugging and Testing Tools

- **Visual Interface**: Intuitive user interface to simplify operations
- **Real-Time Preview**: Instantly view prompt optimization effects
- **History Records**: Save optimization history and support version comparison
- **Export Functionality**: Support exporting optimization results in multiple formats

### üåê Multi-Language Support

- **Language Switching**: Support Chinese and English interface switching
- **Real-Time Translation**: Instant language switching without page refresh
- **Localized Content**: Complete localization of all interface elements
- **Browser Detection**: Automatic language detection based on browser settings

## üõ†Ô∏è Tech Stack

### Backend Technologies

- **Framework**: .NET 9.0 + ASP.NET Core
- **AI Engine**: Microsoft Semantic Kernel 1.54.0
- **Database**: PostgreSQL + Entity Framework Core
- **Authentication**: JWT Token authentication
- **Logging**: Serilog structured logging
- **API Documentation**: Scalar OpenAPI

### Frontend Technologies

- **Framework**: React 19.1.0 + TypeScript
- **UI Components**: Ant Design 5.25.3
- **Routing**: React Router DOM 7.6.1
- **State Management**: Zustand 5.0.5
- **Styling**: Styled Components 6.1.18
- **Build Tool**: Vite 6.3.5

### Core Dependencies

- **AI Model Integration**: OpenAI API compatible interface
- **Real-Time Communication**: Server-Sent Events (SSE)
- **Data Storage**: IndexedDB (client-side caching)
- **Rich Text Editing**: TipTap editor
- **Code Highlighting**: Prism.js + React Syntax Highlighter
- **Internationalization**: React i18next for multi-language support

## üì¶ Deployment Guide

### Environment Requirements

- Docker & Docker Compose
- .NET 9.0 SDK (development environment)
- Node.js 18+ (development environment)

### üöÄ Quick Start

1. Clone the project
   
```bash
git clone https://github.com/AIDotNet/auto-prompt.git
cd auto-prompt
```

2. Deploy using Docker Compose

```bash
# Start services
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f
```

3. Access the application

- Frontend: http://localhost:10426
- API Documentation: http://localhost:10426/scalar/v1

### üîê Default Account Information

After the first deployment, the system will automatically create a default admin account:

- **Username**: `admin`
- **Password**: `admin123`

**Security Notice**: For system security, please change the default password immediately after first login.

You can customize the default account through environment variables:

```yaml
environment:
  - DEFAULT_USERNAME=your_admin_username
  - DEFAULT_PASSWORD=your_secure_password
```


### üîß Development Environment Setup

1. Backend Development

```bash
cd src/Console.Service
dotnet restore
dotnet run
```

2. Frontend Development

```bash
cd web
npm install
npm run dev
```

### üåê Environment Variable Configuration

Configure in `src/Console.Service/appsettings.json`:

```json
{
  "OpenAIEndpoint": "https://api.openai.com/v1",
  "CHAT_MODEL": "gpt-4,gpt-3.5-turbo,claude-3-sonnet",
  "IMAGE_GENERATION_MODEL": "dall-e-3,midjourney,stable-diffusion",
  "DEFAULT_CHAT_MODEL": "gpt-4",
  "DEFAULT_IMAGE_GENERATION_MODEL": "dall-e-3",
  "GenerationChatModel": "gpt-4",
  "ConnectionStrings": {
    "Type": "postgresql",
    "Default": "Host=localhost;Database=prompt_db;Username=postgres;Password=your_password"
  },
  "Jwt": {
    "Key": "your_jwt_secret_key",
    "Issuer": "auto-prompt",
    "Audience": "auto-prompt-users"
  }
}
```

### üîß Custom Endpoint Configuration

This platform supports configuring custom AI API endpoints that are compatible with the OpenAI API format.

#### Configuration Methods

##### 1. Configuration via Configuration File (Recommended for Production)

Configure in `src/Console.Service/appsettings.json`:

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  "OpenAIEndpoint": "https://your-custom-api.com/v1",
  "ConnectionStrings": {
    "Type": "sqlite",
    "Default": "Data Source=/data/ConsoleService.db"
  }
}
```

##### 2. Configuration via Environment Variables

```bash
export OPENAIENDPOINT="https://your-custom-api.com/v1"
```

##### 3. Docker Compose Environment Variable Configuration

Create or modify `docker-compose.yaml`:

```yaml
services:
  console-service:
    image: registry.cn-shenzhen.aliyuncs.com/tokengo/console
    ports:
      - 10426:8080
    environment:
      - TZ=Asia/Shanghai
      - OpenAIEndpoint=https://your-custom-api.com/v1
      # AI Model Configuration
      - CHAT_MODEL=gpt-4,gpt-3.5-turbo,claude-3-sonnet
      - IMAGE_GENERATION_MODEL=dall-e-3,midjourney,stable-diffusion
      - DEFAULT_CHAT_MODEL=gpt-4
      - DEFAULT_IMAGE_GENERATION_MODEL=dall-e-3
      - GenerationChatModel=gpt-4
      # Database Configuration
      - ConnectionStrings:Type=sqlite
      - ConnectionStrings:Default=Data Source=/data/ConsoleService.db
    volumes:
      - ./data:/app/data
    build:
      context: .
      dockerfile: src/Console.Service/Dockerfile
```

#### New Environment Variables Detailed Description

##### AI Model Configuration Variables

- **`CHAT_MODEL`**: Configure the list of chat models supported by the platform, separated by commas. Users can select from these models in the frontend interface.
- **`IMAGE_GENERATION_MODEL`**: Configure the list of image generation models supported by the platform, separated by commas.
- **`DEFAULT_CHAT_MODEL`**: Set the default chat model to use when users don't specify one.
- **`DEFAULT_IMAGE_GENERATION_MODEL`**: Set the default image generation model.
- **`GenerationChatModel`**: Chat model specifically used for prompt optimization and generation features.

#### Supported API Endpoint Types

The platform supports the following services compatible with the OpenAI API format:

- **OpenAI Official API**: `https://api.openai.com/v1`
- **Azure OpenAI**: `https://your-resource.openai.azure.com/openai/deployments/your-deployment`
- **Domestic Proxy Services**:
  - `https://api.token-ai.cn/v1` (default)
  - `https://api.deepseek.com/v1`
  - `https://api.moonshot.cn/v1`
- **Self-hosted Services**:
  - Ollama: `http://localhost:11434/v1`
  - LocalAI: `http://localhost:8080/v1`
  - vLLM: `http://localhost:8000/v1`

#### Complete Docker Compose Configuration Example

##### Basic Configuration (SQLite Database)

```yaml
version: '3.8'

services:
  console-service:
    image: registry.cn-shenzhen.aliyuncs.com/tokengo/console
    container_name: auto-prompt
    ports:
      - "10426:8080"
    environment:
      - TZ=Asia/Shanghai
      - DEFAULT_USERNAME=admin
      - DEFAULT_PASSWORD=admin123
      - OpenAIEndpoint=https://api.openai.com/v1
      - CHAT_MODEL=gpt-4,gpt-3.5-turbo,claude-3-sonnet
      - IMAGE_GENERATION_MODEL=dall-e-3,midjourney,stable-diffusion
      - DEFAULT_CHAT_MODEL=gpt-4
      - DEFAULT_IMAGE_GENERATION_MODEL=dall-e-3
      - GenerationChatModel=gpt-4
      - ConnectionStrings:Type=sqlite
      - ConnectionStrings:Default=Data Source=/data/ConsoleService.db
    volumes:
      - ./data:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

##### Advanced Configuration (PostgreSQL Database)

```yaml
version: '3.8'

services:
  console-service:
    image: registry.cn-shenzhen.aliyuncs.com/tokengo/console
    container_name: auto-prompt
    ports:
      - "10426:8080"
    environment:
      - TZ=Asia/Shanghai
      - DEFAULT_USERNAME=admin
      - DEFAULT_PASSWORD=admin123
      - OpenAIEndpoint=https://your-custom-api.com/v1
      - CHAT_MODEL=gpt-4,gpt-3.5-turbo,claude-3-sonnet
      - IMAGE_GENERATION_MODEL=dall-e-3,midjourney,stable-diffusion
      - DEFAULT_CHAT_MODEL=gpt-4
      - DEFAULT_IMAGE_GENERATION_MODEL=dall-e-3
      - GenerationChatModel=gpt-4
      - ConnectionStrings:Type=postgresql
      - ConnectionStrings:Default=Host=postgres;Database=auto_prompt;Username=postgres;Password=your_password
    depends_on:
      - postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  postgres:
    image: postgres:16-alpine
    container_name: auto-prompt-db
    environment:
      - POSTGRES_DB=auto_prompt
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=your_password
      - TZ=Asia/Shanghai
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```

##### Local AI Service Configuration (Ollama)

```yaml
version: '3.8'

services:
  console-service:
    image: registry.cn-shenzhen.aliyuncs.com/tokengo/console
    container_name: auto-prompt
    ports:
      - "10426:8080"
    environment:
      - TZ=Asia/Shanghai
      - DEFAULT_USERNAME=admin
      - DEFAULT_PASSWORD=admin123
      - OpenAIEndpoint=http://ollama:11434/v1
      - CHAT_MODEL=llama2,codellama,mistral
      - IMAGE_GENERATION_MODEL=stable-diffusion
      - DEFAULT_CHAT_MODEL=llama2
      - DEFAULT_IMAGE_GENERATION_MODEL=stable-diffusion
      - GenerationChatModel=llama2
      - ConnectionStrings:Type=sqlite
      - ConnectionStrings:Default=Data Source=/data/ConsoleService.db
    volumes:
      - ./data:/app/data
    depends_on:
      - ollama
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped
    # Uncomment the following if you have a GPU
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

volumes:
  ollama_data:
```

#### Deployment Steps

1. **Select Configuration Template**
   
   Choose one of the configuration templates above according to your needs and save it as `docker-compose.yaml`.

2. **Modify Configuration Parameters**
   
   ```bash
   # Modify the API endpoint
   - OpenAIEndpoint=https://your-api-endpoint.com/v1
   
   # Modify the database password (if using PostgreSQL)
   - POSTGRES_PASSWORD=your_secure_password
   - ConnectionStrings:Default=Host=postgres;Database=auto_prompt;Username=postgres;Password=your_secure_password
   ```

3. **Start the Service**
   
   ```bash
   # Start all services
   docker-compose up -d
   
   # Check the status of the services
   docker-compose ps
   
   # View logs
   docker-compose logs -f console-service
   ```

4. **Verify Deployment**
   
   ```bash
   # Check the health status of the service
   curl http://localhost:10426/health
   
   # Access the API documentation
   curl http://localhost:10426/scalar/v1
   ```

#### Environment Variable Descriptions

| Variable Name | Description | Default Value | Example |
|---------------|-------------|---------------|---------|
| `OpenAIEndpoint` | AI API endpoint address | `https://api.token-ai.cn/v1` | `https://api.openai.com/v1` |
| `CHAT_MODEL` | Available chat models (comma-separated) | `gpt-4.1,o4-mini,claude-sonnet-4-20250514,claude-3-7-sonnet` | `gpt-4,gpt-3.5-turbo,claude-3-sonnet` |
| `IMAGE_GENERATION_MODEL` | Available image generation models (comma-separated) | `gpt-image-1,dall-e-3,imagen4` | `dall-e-3,midjourney,stable-diffusion` |
| `DEFAULT_CHAT_MODEL` | Default chat model | `gpt-4.1-mini` | `gpt-4` |
| `DEFAULT_IMAGE_GENERATION_MODEL` | Default image generation model | `gpt-4.1` | `dall-e-3` |
| `GenerationChatModel` | Chat model for prompt generation | `gpt-4.1-mini` | `gpt-4` |
| `DEFAULT_USERNAME` | Default admin username | `admin` | `admin`, `root`, `administrator` |
| `DEFAULT_PASSWORD` | Default admin password | `admin123` | `your_secure_password` |
| `ConnectionStrings:Type` | Database type | `sqlite` | `postgresql`, `sqlite` |
| `ConnectionStrings:Default` | Database connection string | `Data Source=/data/ConsoleService.db` | PostgreSQL: `Host=postgres;Database=auto_prompt;Username=postgres;Password=password` |
| `TZ` | Time zone setting | `Asia/Shanghai` | `UTC`, `America/New_York` |

#### Troubleshooting

##### Common Issues

1. **API Endpoint Connection Failure**
   ```bash
   # Check if the endpoint is accessible
   curl -I https://your-api-endpoint.com/v1/models
   
   # Check the container network
   docker-compose exec console-service curl -I http://ollama:11434/v1/models
   ```

2. **Database Connection Failure**
   ```bash
   # Check the PostgreSQL container status
   docker-compose logs postgres
   
   # Test database connection
   docker-compose exec postgres psql -U postgres -d auto_prompt -c "SELECT 1;"
   ```

3. **Permission Issues**
   ```bash
   # Ensure correct permissions for the data directory
   sudo chown -R 1000:1000 ./data
   chmod 755 ./data
   ```

##### Log Viewing

```bash
# View application logs
docker-compose logs -f console-service

# View database logs
docker-compose logs -f postgres

# View all service logs
docker-compose logs -f
```

## üéÆ Usage Guide

### 1. Prompt Optimization

1. Enter the prompt to be optimized in the workbench
2. Describe specific requirements and expected outcomes
3. Choose whether to enable deep reasoning mode
4. Click "Generate" to start the optimization process
5. View optimization results and reasoning process

### 2. Template Management

1. Save optimized prompts as templates
2. Add title, description, and tags
3. Manage personal templates in "My Prompts"
4. Support editing, deleting, and favoriting operations

### 3. Community Sharing

1. Browse popular templates in the prompt plaza
2. Use the search function to find specific types of templates
3. Like and favorite interesting templates
4. Share your high-quality templates with the community

### 4. Language Switching

1. Click the language switcher button (üåê) in the top-right corner or sidebar
2. Select your preferred language (Chinese/English)
3. The interface will switch languages instantly without page refresh
4. Your language preference will be saved for future visits

## ü§ù Contribution Guide

We welcome community contributions! Please follow these steps:

1. **Fork the project** to your GitHub account
2. **Create a feature branch**: `git checkout -b feature/AmazingFeature`
3. **Commit your changes**: `git commit -m 'Add some AmazingFeature'`
4. **Push the branch**: `git push origin feature/AmazingFeature`
5. **Create a Pull Request**

### Development Standards

- Follow existing code style and naming conventions
- Add appropriate comments and documentation
- Ensure all tests pass
- Update related documentation

## üìÑ Open Source License

This project is licensed under the **LGPL (Lesser General Public License)**.

### License Terms

- ‚úÖ **Commercial Use**: Allows deployment and use in commercial environments
- ‚úÖ **Distribution**: Allows distribution of original code and binaries
- ‚úÖ **Modification**: Allows modification of source code for personal or internal use
- ‚ùå **Commercial Distribution After Modification**: Prohibits commercial distribution of modified source code
- ‚ö†Ô∏è **Liability**: Use of this software is at the user's own risk

### Important Notes

- Direct deployment of this project for commercial use is allowed
- Development of internal tools based on this project is allowed
- Modified source code cannot be redistributed
- Original copyright statements must be retained

For detailed license terms, please refer to the [LICENSE](LICENSE) file.

## üôè Acknowledgments

Thanks to the following open source projects and technologies:

- [Microsoft Semantic Kernel](https://github.com/microsoft/semantic-kernel) - AI orchestration framework
- [Ant Design](https://ant.design/) - React UI component library
- [React](https://reactjs.org/) - Frontend framework
- [.NET](https://dotnet.microsoft.com/) - Backend framework

## üìû Contact Us

- **Project Homepage**: https://github.com/AIDotNet/auto-prompt
- **Issue Reporting**: [GitHub Issues](https://github.com/AIDotNet/auto-prompt/issues)
- **Official Website**: https://token-ai.cn
- **Technical Support**: Submit via GitHub Issues

---

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=AIDotNet/auto-prompt&type=Date)](https://www.star-history.com/#AIDotNet/auto-prompt&Date)

## üíåWeChat

![image](img/wechat.jpg)


<div align="center">

**If this project helps you, please give us a ‚≠ê Star!**

Made with ‚ù§Ô∏è by [TokenAI](https://token-ai.cn)

</div>
